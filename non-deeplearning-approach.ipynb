{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"251261c1f546a58f9798d28eacbe6d9791d75468"},"cell_type":"markdown","source":"## Getting Started\nThanks to wonderful python libraries and packages for making our life easier."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# nlp\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \nfrom gensim.models.word2vec import Word2Vec\nimport spacy\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.text import text_to_word_sequence\n\n#utils\nfrom collections import Counter, defaultdict\nimport gc, time\nfrom tqdm import tqdm\n\n#visualization\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\nimport seaborn as sns\n\n# some basic ml models and metrics evaluation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom scikitplot.metrics import plot_confusion_matrix\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.utils.fixes import signature\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import mean_squared_error\n\n#ensembles\nimport xgboost as xgb\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c11c29912c9bd099637ecd3e79c4a4746b6f3d8"},"cell_type":"markdown","source":"Let's get some idea about the data that we are dealing."},{"metadata":{"trusted":true,"_uuid":"7c9fdc58363e56e100df64bbf5a7699561a79b76"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n# Looking the data\nprint(\"Train shape : \", train.shape)\nprint(\"Test shape : \", test.shape)\ndist = train['target'].value_counts()\nsns.barplot(x=np.arange(2), y=dist)\nplt.title(\"Distribution of positive and negative labels\")\nplt.xlabel(\"target\")\nplt.ylabel(\"Count\")\nplt.show()\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b86e5316853672937b02be4fc624ba0fee7a9b3b"},"cell_type":"code","source":"# keep some validation set\ntrain_df, val_df = train_test_split(train, test_size=0.1, random_state=33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0809b070fdae774e45da68157e375c120f5f0a8d"},"cell_type":"code","source":"train_text = train['question_text']\ntest_text = test['question_text']\nall_text = pd.concat([train_text, test_text])\ny = train_df.target.values\nyde = val_df.target.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bd1f06d0add6accfc3e02c2d58e7089a68805fc"},"cell_type":"markdown","source":"## Utils"},{"metadata":{"trusted":true,"_uuid":"16ea721b5753841b3aed97b7211434d9a2f515b7"},"cell_type":"code","source":"def evaluatePredictions(y, pred, silent=False):\n    f1_list = list()\n    thre_list = np.arange(0.1, 0.901, 0.01)\n    for thresh in thre_list:\n        thresh = np.round(thresh, 2)\n        f1 = f1_score(y, (pred>thresh).astype(int))\n        f1_list.append(f1)\n        if not silent:\n            print(\"F1 score at threshold {0} is {1}\".format(thresh, f1))\n    #return f1_list\n    plot_confusion_matrix(y, np.array(pd.Series(pred.reshape(-1,)).map(lambda x:1 if x>thre_list[np.argmax(f1_list)] else 0)))\n    best = thre_list[np.argmax(f1_list)]\n    best = np.round(best, 2)\n    score = np.max(f1_list)\n    print('Best Threshold: ', best)\n    print('Best F1 Score: ', score)\n    return best, score\n\ndef plotPrecisionRecall(y, pred):\n    precision, recall, _ = precision_recall_curve(y, pred)\n    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n    step_kwargs = ({'step': 'post'}\n                   if 'step' in signature(plt.fill_between).parameters\n                   else {})\n    plt.step(recall, precision, color='b', alpha=0.2,\n             where='post')\n    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    average_precision = average_precision_score(y, pred)\n    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n              average_precision))\n\ndef performKfCV(kf, models, X, y, Xde):\n    preds = {}\n    de_preds = 0\n    tr_preds = np.zeros([X.shape[0],])\n    for name in models.keys():\n        preds[name] = (tr_preds, de_preds)\n    for i, (train_index, val_index) in tqdm(enumerate(kf.split(X))):\n        Xtrain, Xval = X[train_index], X[val_index]\n        Ytrain, Yval = y[train_index], y[val_index]\n        for name, model in models.items():\n            model.fit(Xtrain,Ytrain)\n            val_preds = model.predict_proba(Xval)[:,1]\n            cv_pred, de_pred = preds[name]\n            cv_pred[val_index]=val_preds\n            de_pred += 0.2*model.predict_proba(Xde)[:,1]\n            preds[name] = (cv_pred, de_pred)\n    return preds\n    \nstop_words = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aae43c8573df45a68552078fe9f0a65427d91b00"},"cell_type":"markdown","source":"## Feature extraction and baseline techniques\nLet's start by very simple feature extraction Bags of Words (with count) and TFIDF and see how some popular methods for text classification like Naive Bayes, Linear models and Decision trees perform. Then I will experiment with embeddings and see how some approaches work.\n\n>Although, SVMs are considered state-of-art for text classifications, the number of examples is too high (big data problem).  There will be a lot of support vectors and learning will take long time and model will also be large.\n"},{"metadata":{"_uuid":"890903cf4bd322d3e8a38f352c6411d64db13b33"},"cell_type":"markdown","source":"### Naive Bayes with Bag of words\n> According to documentation of Naive Bayes it performs best for bag of words like features."},{"metadata":{"trusted":true,"_uuid":"90eb7a2ebe17e0c131cef4c2ef3afe51efab18c1"},"cell_type":"code","source":"cntVect = CountVectorizer(binary=True, stop_words=stop_words,\n                             preprocessor=lambda x: \" \".join(text_to_word_sequence(x)),\n                             token_pattern=\"[a-zA-Z]{2,}\",\n                             min_df=5, max_df=0.99)\nmult_nb = MultinomialNB()\nbern_nb = BernoulliNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7dc51590123dd33a095930771afa2000199544d"},"cell_type":"code","source":"cntVect.fit(all_text)\nX = cntVect.transform(train_df.question_text)\nXde = cntVect.transform(val_df.question_text)\nXte = cntVect.transform(test_text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52dece7faa10005c05d15afe4a24a02c696a0b9e"},"cell_type":"markdown","source":"**Running a 5 fold cross validation to obtain  F1 score**. Since, the data is highly imbalanced, F1 score will be better than accuracy."},{"metadata":{"trusted":true,"_uuid":"6c04a0fe469aad06943fda201bb5b02cb8289544","scrolled":false},"cell_type":"code","source":"nb_models = {\n    \"mult_nb\": mult_nb,\n    \"bern_nb\": bern_nb\n}\nkf = KFold(n_splits=5, shuffle=True, random_state=33)\nnb_preds = performKfCV(kf, nb_models, X, y, Xde)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe8c0bbf312e94c1db4bd01fa478e7e72e7ddbc8"},"cell_type":"code","source":"thresholds = {}\nscores = {}\nfor name,(cv_pred, de_pred) in nb_preds.items():\n    print(name)\n    print(\"Cross validation F1 score\")\n    thresholdNb = evaluatePredictions(y, cv_pred, silent=True)\n    print(\"Development set F1 score\")\n    thresholdNb, scoreNb = evaluatePredictions(yde, de_pred, silent=True)\n    thresholds[name] = thresholdNb\n    scores[name] = scoreNb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f4d995e0da45325958e0e0adf06d1ce8d5854fe"},"cell_type":"markdown","source":"**Combining predictions of two naive bayes models**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f988dd8b5e53de111247ae5c05644205d22945a4"},"cell_type":"code","source":"# combining\nweights_nb = {\n    \"mult_nb\": 0.5,\n    \"bern_nb\": 0.5\n}\ncom_cv_pred=0\ncom_de_pred=0\nfor name,(cv_pred, de_pred) in nb_preds.items():\n    com_cv_pred += weights_nb[name]*cv_pred\n    com_de_pred += weights_nb[name]*de_pred\nprint(\"Cross validation F1 score\")\nthresholdNb = evaluatePredictions(y, com_cv_pred, silent=True)\nprint(\"Development set F1 score\")\nthresholdNb,scoreNb = evaluatePredictions(yde, com_de_pred, silent=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af3a48661b594f396663f47274768f0f3c0cc3e1"},"cell_type":"code","source":"barx = [name for name,_ in scores.items()]\nbarx.append(\"combined_nb\")\nbary = [score for _,score in scores.items()]\nbary.append(scoreNb)\nsns.lineplot(x=barx, y=bary)\nplt.xlabel(\"Model\")\nplt.ylabel(\"F1 Score\")\nplt.title(\"Naive Bayes Models F1 Score using BOW for validation set data\")\nplt.show()\nfor name, (cv_pred, de_pred) in nb_preds.items():\n    print(name)\n    plotPrecisionRecall(yde, de_pred)\n    plt.show()\nprint(\"combined_nb\")\nplotPrecisionRecall(yde, com_de_pred)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"995f735fec560d902801acad4488b5a1852c9757"},"cell_type":"markdown","source":"**Trying Linear models**"},{"metadata":{"trusted":true,"_uuid":"798d79ba60e66ae6dc91caf095f1d98526e75183"},"cell_type":"code","source":"cntVect = CountVectorizer(binary=False, stop_words=stop_words,\n                             preprocessor=lambda x: \" \".join(text_to_word_sequence(x)),\n                             token_pattern=\"[a-zA-Z]{2,}\",\n                             min_df=5, max_df=0.99)\ntfidfVect = TfidfVectorizer(binary=False, stop_words=stop_words,\n                             preprocessor=lambda x: \" \".join(text_to_word_sequence(x)),\n                             token_pattern=\"[a-zA-Z]{2,}\",\n                             min_df=5, max_df=0.99)\nln_cnt_models = {}\nln_tfidf_models = {}\nCs = [0.1, 1, 10]\nfor c in Cs:\n    ln_cnt_models[\"cnt_log_\"+str(c)] = LogisticRegression(random_state=333,\n                                                          class_weight=\"balanced\",\n                                                          verbose=0, C=c, solver='lbfgs', n_jobs=1)\n    ln_tfidf_models[\"tfidf_log_\"+str(c)] = LogisticRegression(random_state=333,\n                                                              class_weight=\"balanced\",\n                                                              verbose=0, C=c, solver='lbfgs', n_jobs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75c3b722923828224b4e285688751026e2eb84be"},"cell_type":"code","source":"cntVect.fit(all_text) #exploiting all given data\nX = cntVect.transform(train_df.question_text)\nXde = cntVect.transform(val_df.question_text)\nXte = cntVect.transform(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adb9acc5a20e58d222a90069170d1f2c03e2a594"},"cell_type":"code","source":"LogisticRegression?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03874a9d4183f786eeb882f1d2b14b949373556e"},"cell_type":"code","source":"ln_cnt_preds = performKfCV(kf, ln_cnt_models, X, y, Xde)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"127ee393ab15b1b0b87dc725c6e0885057f47a87"},"cell_type":"code","source":"for name,(cv_pred, de_pred) in ln_cnt_preds.items():\n    print(name)\n    print(\"Cross validation F1 score\")\n    thresholdNb = evaluatePredictions(y, cv_pred, silent=True)\n    print(\"Development set F1 score\")\n    thresholdNb, scoreNb = evaluatePredictions(yde, de_pred, silent=True)\n    thresholds[name] = thresholdNb\n    scores[name] = scoreNb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e78843bf7d6b99628c87e185e63f141b7a956b10"},"cell_type":"code","source":"com_cv_pred=0\ncom_de_pred=0\nfor name,(cv_pred, de_pred) in ln_cnt_preds.items():\n    com_cv_pred += 1/len(ln_cnt_preds)*cv_pred\n    com_de_pred += 1/len(ln_cnt_preds)*de_pred\nprint(\"Cross validation F1 score\")\nthresholdNb = evaluatePredictions(y, com_cv_pred, silent=True)\nprint(\"Development set F1 score\")\nthresholdNb,scoreNb = evaluatePredictions(yde, com_de_pred, silent=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2ed5f749a2e8ee8604cf1ecada8cfea46d9323e","scrolled":true},"cell_type":"code","source":"barx = [name for name,_ in scores.items()]\nbary = [score for _,score in scores.items()]\nsns.lineplot(x=barx, y=bary, markers=True)\nplt.xlabel(\"Model\")\nplt.ylabel(\"F1 Score\")\nplt.title(\"F1 Score using different models for validation set data\")\nplt.show()\nscoresObj = [(name,score) for name,score in scores.items()]\nprint (tabulate(scoresObj, floatfmt=\".4f\", headers=(\"model\", 'F1 score')))\n# for name, (cv_pred, de_pred) in ln_cnt_preds.items():\n#     print(name)\n#     plotPrecisionRecall(yde, de_pred)\n#     plt.show()\n# print(\"combined_ln_cnt\")\n# plotPrecisionRecall(yde, com_de_pred)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff229b8cd399a78830a7ca8c3f00d85c0750b0eb"},"cell_type":"code","source":"tfidfVect.fit(all_text) #exploiting all given data\nX = tfidfVect.transform(train_df.question_text)\nXde = tfidfVect.transform(val_df.question_text)\nXte = tfidfVect.transform(test_text)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfeb439449c2c552467f0a2ae7b6ccbe78a41623"},"cell_type":"code","source":"ln_tfidf_preds = performKfCV(kf, ln_tfidf_models, X, y, Xde)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bea8691c359e4219d089dcfb393ed9bbf9f10dd"},"cell_type":"code","source":"for name,(cv_pred, de_pred) in ln_tfidf_preds.items():\n    print(name)\n    print(\"Cross validation F1 score\")\n    thresholdNb = evaluatePredictions(y, cv_pred, silent=True)\n    print(\"Development set F1 score\")\n    thresholdNb, scoreNb = evaluatePredictions(yde, de_pred, silent=True)\n    thresholds[name] = thresholdNb\n    scores[name] = scoreNb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fde291d57615518b35f5cd56db10f6ef80132ef"},"cell_type":"code","source":"com_cv_pred=0\ncom_de_pred=0\nfor name,(cv_pred, de_pred) in ln_tfidf_preds.items():\n    com_cv_pred += 1/len(ln_tfidf_preds)*cv_pred\n    com_de_pred += 1/len(ln_tfidf_preds)*de_pred\nprint(\"Cross validation F1 score\")\nthresholdNb = evaluatePredictions(y, com_cv_pred, silent=True)\nprint(\"Development set F1 score\")\nthresholdNb,scoreNb = evaluatePredictions(yde, com_de_pred, silent=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9dc9facb3c34770a0c5c17b56ebfdbf9c5905cf"},"cell_type":"code","source":"barx = [name for name,_ in scores.items()]\nbary = [score for _,score in scores.items()]\nsns.lineplot(x=barx, y=bary)\nplt.xlabel(\"Model\")\nplt.ylabel(\"F1 Score\")\nplt.title(\"F1 Score using different models for validation set data\")\nplt.show()\nscoresObj = [(name,score) for name,score in scores.items()]\nprint (tabulate(sorted(scoresObj, key=lambda x: -x[1]), floatfmt=\".4f\", headers=(\"model\", 'F1 score')))\n# for name, (cv_pred, de_pred) in ln_cnt_preds.items():\n#     print(name)\n#     plotPrecisionRecall(yde, de_pred)\n#     plt.show()\n# print(\"combined_ln_cnt\")\n# plotPrecisionRecall(yde, com_de_pred)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4096e4efdac1e8571e0c176c53b36e28656355c4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9a236f8d24fa2646a6cc031b1629ae2d4d3a999"},"cell_type":"markdown","source":"**Decision trees**"},{"metadata":{"trusted":true,"_uuid":"59d56042e515c8bd211261b7ea1f539240eafa4f","_kg_hide-output":true},"cell_type":"code","source":"\ncntVect = CountVectorizer(binary=True, stop_words=stop_words,\n                             preprocessor=lambda x: \" \".join(text_to_word_sequence(x)),\n                             token_pattern=\"[a-zA-Z]{2,}\",\n                             min_df=5, max_df=0.99)\n\ntree_models = {}\ndepths = [3,5,7]\nfor depth in depths:\n    tree_models[\"dt_\"+str(depth)] = DecisionTreeClassifier(random_state=333, class_weight=\"balanced\", max_depth=depth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7b2b3d4006530c5448fff87fbda61e2aae71bfe"},"cell_type":"code","source":"cntVect.fit(all_text) #exploiting all given data\nX = cntVect.transform(train_df.question_text)\nXde = cntVect.transform(val_df.question_text)\nXte = cntVect.transform(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01ef48004640c98bd1543d14f4ffa320be946291"},"cell_type":"code","source":"dt_preds = performKfCV(kf, tree_models, X, y, Xde)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a34e70a4e45751fa1cba4c10c9f9fbec724f7b5b"},"cell_type":"code","source":"for name,(cv_pred, de_pred) in dt_preds.items():\n    print(name)\n    print(\"Cross validation F1 score\")\n    thresholdNb = evaluatePredictions(y, cv_pred, silent=True)\n    print(\"Development set F1 score\")\n    thresholdNb, scoreNb = evaluatePredictions(yde, de_pred, silent=True)\n    thresholds[name] = thresholdNb\n    scores[name] = scoreNb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fabf808ea526c0c82e4d16c4ecedca0cc048a6c3"},"cell_type":"markdown","source":"**Let's try to combine all the independent predictions (Naive ensemble)**"},{"metadata":{"trusted":true,"_uuid":"1351435be0268512fe9f6a456442fa4d4c236954"},"cell_type":"code","source":"all_preds = [nb_preds, ln_cnt_preds, ln_tfidf_preds, dt_preds] #ignoring dt_trees now. We will use xgboost later\ntrain_stack = None\nval_stack = None\nfor preds in all_preds:\n    for name, (cv_preds, de_preds) in preds.items():\n        print(\"stacking \", name)\n        if train_stack is None:\n            train_stack = (cv_preds.reshape(-1,1))\n            val_stack = (de_preds.reshape(-1,1))\n        else:\n            train_stack = np.hstack((train_stack, (cv_preds.reshape(-1,1))))\n            val_stack = np.hstack((val_stack, (de_preds.reshape(-1,1))))\n\n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbd7681bc8efc60f6893145cd3adf518cc543cf3"},"cell_type":"markdown","source":"**Finding best C**"},{"metadata":{"trusted":true,"_uuid":"a906fb8303f350f428450f7a8cd9f2937585974c"},"cell_type":"code","source":"Cs = [0.0001, 0.001, 0.01]\nensembled_models = {}\nfor c in Cs:\n    ensembled_models[\"combiner_ln_\"+str(c)] = LogisticRegression(class_weight = \"balanced\", C=c, solver='lbfgs', verbose=1)\nen_preds = performKfCV(kf, ensembled_models, train_stack, y, val_stack)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6401d817c30e1bcc4eb039ca4942f192e192accd"},"cell_type":"code","source":"for name,(cv_pred, de_pred) in en_preds.items():\n    print(name)\n    print(\"Cross validation F1 score\")\n    thresholdNb = evaluatePredictions(y, cv_pred, silent=True)\n    print(\"Development set F1 score\")\n    thresholdNb, scoreNb = evaluatePredictions(yde, de_pred, silent=True)\n    thresholds[name] = thresholdNb\n    scores[name] = scoreNb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d41d03f258efb5536de9939a51294708823d527"},"cell_type":"markdown","source":"**Using C determined from above to combine all predictions**"},{"metadata":{"trusted":true,"_uuid":"043c9710446da798d62153fb16fd380ac457fab1"},"cell_type":"code","source":"classifier = LogisticRegression(class_weight = \"balanced\", C=0.0001, solver='lbfgs', verbose=1)\nclassifier.fit(train_stack, y)\ntr_preds = classifier.predict_proba(train_stack)[:,1]\nval_preds = classifier.predict_proba(val_stack)[:,1]\nevaluatePredictions(y, tr_preds, silent=True)\nevaluatePredictions(yde, val_preds, silent=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c7a2c50d04297ed138389871e9a1e34421be989"},"cell_type":"markdown","source":"# F1 score is < 0.6 for all baseline methods and its combinations"},{"metadata":{"_uuid":"a70eed6d95188bed8e3ea292576ff91f5bb0a391"},"cell_type":"markdown","source":" **Let's see if XGBOOST, a sophisticated boosting algorithm,  will work better?**"},{"metadata":{"trusted":true,"_uuid":"d90f1a337100369bc045d8e75a1427e4d4a8927c"},"cell_type":"markdown","source":"X = train_df.question_text\ny = train_df.target\ncntVectBin = CountVectorizer(binary=False, stop_words=stop_words,\n                             preprocessor=lambda x: \" \".join(text_to_word_sequence(x)),\n                             token_pattern=\"[a-zA-Z]{2,}\",\n                             min_df=5, max_df=0.99)\nXt = cntVectBin.fit_transform(X)\nXv = cntVectBin.transform(val_df.question_text)\nYt = y\nYv = val_df.target"},{"metadata":{"_uuid":"ce4c74299e2c58f6aa3fb059c26fc92d0e39f56b"},"cell_type":"markdown","source":"Using native xgb library instead of Sklearn wrapper as it has more documentation and more features"},{"metadata":{"trusted":true,"_uuid":"1f7b42e133e7b9dfa644b26b7b1e2a68582badf4"},"cell_type":"markdown","source":"# custom evaluation metric\ndef f1score(pred_probs, dtrain):\n    labels = dtrain.get_label() # obtain true labels\n    thresh = 0.8 # threshold for f1 score, previous observations\n    f1 = f1_score(labels, (pred_probs>thresh).astype(int))\n    return 'F1_Score', f1"},{"metadata":{"trusted":true,"_uuid":"20c18720078178e1c2ef3b0e7e7add49edcacf23"},"cell_type":"markdown","source":"xgbTrain = xgb.DMatrix(Xt, label=Yt)\nxgbVal = xgb.DMatrix(Xv, label=Yv)\nratio = np.count_nonzero(Yt==0)/np.count_nonzero(Yt==1) # we will not have divide by zero error\nprint(ratio)\n# specify training parameters\nparams = {\n    'booster': 'gbtree',\n    'objective':'binary:logistic', # this is classification\n    'max_depth':5, # max depth of decision trees stubs (we have large data so 5 may be reasonable)\n    'silent':1, # don't want any noise on console\n    'eta':0.9, # aggressive learning rate, decided by seeing progress for data in verbose mode \n    'scale_pos_weight': ratio, # handling imbalanced data\n    'lambda': 3, # L2 regularization, need tuning\n    'alpha':1,\n    'eval_metric': ['logloss'],\n    # hyperparameters to be tuned. Gives some taste similar to bagging\n    'max_delta_step': 1,\n    'subsample':0.9,\n    'colsample_bytree': 0.9,\n    'colsample_bylevel': 0.9,\n    'seed':300\n}\nnum_rounds = 1000\nwatchlist  = [(xgbVal,'test'), (xgbTrain,'train')]"},{"metadata":{"trusted":true,"_uuid":"1bc657c89ecb1e2f1de03cead20a1fcd8f3a2959"},"cell_type":"markdown","source":"xgbModel1 = xgb.train(params, xgbTrain, num_rounds, watchlist, verbose_eval=10, feval=f1score, maximize=True)\n"},{"metadata":{"trusted":true,"_uuid":"dbaac3b01c5452acea0a62cd7568730dba5e19aa","scrolled":false},"cell_type":"markdown","source":"xgb_predicted = xgbModel1.predict(xgbVal)\nprint(xgb_predicted)\nevaluatePredictions(Yv, xgb_predicted)"},{"metadata":{"trusted":true,"_uuid":"34429065fcf0d237cece77c6d5cd2c99006c26f4"},"cell_type":"markdown","source":"importances = xgbModel1.get_fscore()\nterms = np.array(list(cntVectBin.vocabulary_.keys()))\nindices = np.array(list(cntVectBin.vocabulary_.values()))\ninverse_vocabulary = terms[np.argsort(indices)]\nreal_word = []\nfor key in list(importances.keys()):\n    nkey = key.replace(\"f\",\"\")\n    real_word.append(inverse_vocabulary[int(nkey)])\n\nimportance_df = pd.DataFrame({\n        'Splits': list(importances.values()),\n        'Feature': real_word\n    })\nimportance_df.sort_values(by='Splits', inplace=True, ascending=False)\n# importance_df.head()\nimportance_df[:20].plot(kind='barh', x='Feature', figsize=(8,6), color='green')\nplt.title(\"Top 20 words that are used in split\")\nplt.show()"},{"metadata":{"trusted":true,"_uuid":"33183eeb3125cc8e5d7582471ef0be373524405b"},"cell_type":"markdown","source":"featmap_df = pd.DataFrame({\n    'index': np.arange(0,len(inverse_vocabulary)),\n        'words': inverse_vocabulary\n    })\nfeatmap_df[\"type\"] = \"i\"\nnp.savetxt(\"featmap.txt\", featmap_df.values, fmt='%s')"},{"metadata":{"trusted":true,"_uuid":"bc4edd33cfb90fe8923577487667f9dc6568fc62"},"cell_type":"markdown","source":"xgb.to_graphviz(xgbModel1, num_trees=10, fmap=\"featmap.txt\")"},{"metadata":{"_uuid":"ff30d875498a620b47429a6f43f83397d99e60a8"},"cell_type":"markdown","source":"**LightGBM alternative to XGBoost?**"},{"metadata":{"trusted":true,"_uuid":"fcf35949699b1221def723290f86c1542690853a"},"cell_type":"code","source":"X = train_df.question_text\ny = train_df.target\ncntVectBin = CountVectorizer(binary=True, stop_words=stop_words,\n                             preprocessor=lambda x: \" \".join(text_to_word_sequence(x)),\n                             token_pattern=\"[a-zA-Z]{2,}\",\n                             min_df=5, max_df=0.99, dtype=np.float32)\ncntVectBin.fit(all_text)\nXt = cntVectBin.transform(X)\nXv = cntVectBin.transform(val_df.question_text)\nYt = y\nYv = val_df.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0271dba4404518b43d3279770d555d320fa2bf3"},"cell_type":"code","source":"terms = np.array(list(cntVectBin.vocabulary_.keys()))\nindices = np.array(list(cntVectBin.vocabulary_.values()))\ninverse_vocabulary = terms[np.argsort(indices)]\nlen(inverse_vocabulary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d99d959d69c7a68785a95f01ce44764226d4c416"},"cell_type":"code","source":"# custom evaluation metric\ndef f1score(pred_probs, dtrain):\n    labels = dtrain.get_label() # obtain true labels\n    thresh = 0.23 # threshold for f1 score, previous observations\n    if len(pred_probs)>0:\n        f1 = f1_score(labels, (pred_probs>thresh).astype(int))\n    else:\n        f1 = 0\n    return 'F1_Score', f1, True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e34c061c69b5ef676beec384246ff0ab524a7ed"},"cell_type":"code","source":"lgbTrain = lgb.Dataset(Xt, label=Yt, silent=1)\nlgbVal = lgb.Dataset(Xv, label=Yv, silent=1)\nratio = np.count_nonzero(Yt==0)/np.count_nonzero(Yt==1) # we will not have divide by zero error\nprint(ratio)\nparams = {\n    'objective':'xentropy', \n#     'objective':'binary', # this is classification\n#     'boosting':'random_forest', #type of boosting (default: gbdt)\n    'num_leaves': 16, # hyperparameter to tune\n    'num_threads':4,\n    'min_data_in_leaf': 25, # support for decision (generalization), (to be tuned)\n    'max_depth':10, # max depth of decision trees stubs, (to be tuned)\n    'eta':0.9, # aggressive learning rate, decided by seeing progress for data in verbose mode \n    'scale_pos_weight': ratio, # handling imbalanced data\n    'lambda': 3, # L2 regularization, need tuning\n    'metric': ['auc','xentropy'],\n    'max_delta_step': 1, # hyperparameters to be tuned. Gives some taste of bagging\n    'subsample':0.9, # bagging fraction\n    'bagging_freq':5, # how often to do bagging\n    'colsample_bytree': 0.9,\n    'seed':300\n}\nnum_rounds = 500","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b356549771f5854e701d7f3ca17d9634335a98e"},"cell_type":"code","source":"evals_result = {}\nlgbModel = lgb.train(params, lgbTrain, num_rounds,valid_sets=[lgbTrain, lgbVal],\n                     valid_names=[\"train\", \"test\"],\n                     verbose_eval=10,evals_result=evals_result,\n                     feature_name=list(inverse_vocabulary))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62afa6c74ee9836c52c6c5fc69b02990df5ffe17","scrolled":true},"cell_type":"code","source":"def showEvals(evals_result):\n    test_f1score = evals_result[\"test\"][\"xentropy\"]\n    train_f1score = evals_result[\"train\"][\"xentropy\"]\n    test_auc = evals_result[\"test\"][\"auc\"]\n    train_auc = evals_result[\"train\"][\"auc\"]\n    print(len(test_f1score))\n    print(len(train_f1score))\n    plt.xlabel(\"Number of estimators\")\n    plt.ylabel(\"Cross Entropy\")\n    plt.plot(np.arange(1,len(test_f1score)+1), test_f1score, label=\"validation\")\n    plt.plot(np.arange(1,len(train_f1score)+1), train_f1score, label=\"train\")\n    plt.legend()\n    plt.show()\n    plt.xlabel(\"Number of estimators\")\n    plt.ylabel(\"AUC\")\n    plt.plot(np.arange(1,len(test_auc)+1), test_auc, label=\"validation\")\n    plt.plot(np.arange(1,len(train_auc)+1), train_auc, label=\"train\")\n    plt.legend()\n    plt.show()\nshowEvals(evals_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3e28c3c617c92ea5cee5d9077a24c46afe533b2"},"cell_type":"code","source":"lgb_predicted = lgbModel.predict(Xv)\nprint(lgb_predicted)\nevaluatePredictions(Yv, lgb_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0171356b363e1e70967cdd05d7682ca9ea2c1909"},"cell_type":"code","source":"lgb.plot_importance(lgbModel, max_num_features=20, title=\"Feature importance by split\")\nlgb.plot_importance(lgbModel, max_num_features=20, importance_type='gain', precision=1, title=\"Feature importance by gain\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"569a1e12342b330010f9456acee77a436b6b6f95"},"cell_type":"code","source":"lgb.create_tree_digraph(lgbModel, precision=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b14f8de03c411be0074bc76402555290e36a574c"},"cell_type":"markdown","source":"## Analysis\n**LightGBM is very similar to XGBoost and performing similar (or better). The advantage with LightGBM is that it is faster. Using cross validation with LightGBM may be good idea. It seems that varying max_depth of tree (num_leaves) and min_data_in_leaf may give some interesting trees providing insights about data.**\n\nBefore that, let's summarize the observations.\n\n1. Data is imbalanced, so accuracy paradox is introduced i.e. better accuracy will not better denote quality of classification. Thus, we need to rely on measures like AUC and F1 score.\n2. Naive Bayes with BOW models had F1 scores around 54% to 55%.\n3. Logistic Regression Classifer (Linear Models) had F1 scores of about 59% for BOW with counts and 58% for TFIDF features.\n4. Decision trees stubs had F1 scores about 32%.\n5. XGBoost (using gradient boosted DTs) was slow to train and had many hyperparameters. The settings gave F1 score of about 59%.\n6. Light GBM seems to be better alternative to XGBoost, given its similarity in performance with XGBoost but with faster speed. A specific settings of hyperparameters touched 60% F1 Score."},{"metadata":{"trusted":true,"_uuid":"57c35a1a914ef94f7238dd880e3802ffcebb27d4"},"cell_type":"code","source":"X = train_df.question_text\ny = train_df.target\ncntVectBin = CountVectorizer(binary=True, stop_words=stop_words,\n                             preprocessor=lambda x: \" \".join(text_to_word_sequence(x)),\n                             token_pattern=\"[a-zA-Z]{2,}\",\n                             min_df=5, max_df=0.99, dtype=np.float32)\ncntVectBin.fit(all_text)\nXt = cntVectBin.transform(X)\nXv = cntVectBin.transform(val_df.question_text)\nYt = y\nYv = val_df.target\nXtest = cntVectBin.transform(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"187792933934ebeee21dc9fa6519ee15a526cda1"},"cell_type":"code","source":"terms = np.array(list(cntVectBin.vocabulary_.keys()))\nindices = np.array(list(cntVectBin.vocabulary_.values()))\ninverse_vocabulary = terms[np.argsort(indices)]\nlen(inverse_vocabulary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83da8aa75f040385d9cc143456285974d6c53030"},"cell_type":"code","source":"lgb_models = {}\n# Here if number of leaves is small, we need more support (min_data_in_leaf)\nratio = np.count_nonzero(Yt==0)/np.count_nonzero(Yt==1) # we will not have divide by zero error\nprint(ratio)\ndefault_params = {\n    'objective':'xentropy', \n#     'objective':'binary', # this is classification\n#     'boosting':'random_forest', #type of boosting (default: gbdt)\n    'num_threads':4,\n    'max_depth':20, # max depth of decision trees stubs, (to be tuned)\n    'eta':0.9, # aggressive learning rate, decided by seeing progress for data in verbose mode \n    'scale_pos_weight': ratio, # handling imbalanced data\n    'lambda': 3, # L2 regularization, need tuning\n    'metric': ['auc','xentropy'],\n    'max_delta_step': 1, # hyperparameters to be tuned. Gives some taste of bagging\n    'subsample':0.9, # bagging fraction\n    'bagging_freq':2, # how often to do bagging\n    'colsample_bytree': 0.9,\n    'seed':333\n}\nnum_rounds = 200\n# num_leaves:min_data_in_leaf:max_depth\nhyParams = {\n    8:30, # most general things\n    16:25, # a bit more specific and so on\n    32:20,\n    64:10,\n    100:5\n}\nfor num_leaves, min_data_in_leaf in hyParams.items():\n    lgb_models[\"lgb_\"+str(num_leaves)+\"_\"+str(min_data_in_leaf)] = None\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1a2bf8b8450c16d50fff9fc62cc4e944f591d48","scrolled":true},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=333)\nevals_result = {}\n\ndef performKfCVLGB(kf, models, X, y, Xde):\n    y = y.values\n    preds = {}\n    de_preds = 0\n    tr_preds = np.zeros([X.shape[0],])\n    for name in models.keys():\n        preds[name] = (tr_preds, de_preds)\n    for i, (train_index, val_index) in tqdm(enumerate(kf.split(X))):\n        Xtrain, Xval = X[train_index], X[val_index]\n        Ytrain, Yval = y[train_index], y[val_index]\n        print(type(Xtrain))\n        lgbTrain = lgb.Dataset(Xtrain, label=Ytrain, silent=1)\n        lgbVal = lgb.Dataset(Xval, label=Yval, silent=1)\n        for name, model in models.items():\n            ev_res = {}\n            print(name)\n            parts = name.split(\"_\", -1)\n            par = default_params.copy()\n            par[\"num_leaves\"] = int(parts[1])\n            par[\"min_data_in_leaf\"] = int(parts[2])\n            print(par)\n            if model is None:\n                lgb_models[name]=[]\n            model = lgb.train(par, lgbTrain, num_rounds,valid_sets=[lgbTrain, lgbVal],\n                     valid_names=[\"train\", \"test\"],\n                     verbose_eval=50, evals_result=ev_res,\n                     feature_name=list(inverse_vocabulary))\n            md_list = lgb_models[name]\n            md_list.append(model)\n            lgb_models[name] = md_list\n            evals_result[name] = ev_res\n            val_preds = model.predict(Xval)\n            cv_pred, de_pred = preds[name]\n            cv_pred[val_index]=val_preds\n            de_pred += 0.2*model.predict(Xde)\n            preds[name] = (cv_pred, de_pred)\n    return preds\n\nlgb_preds = performKfCVLGB(kf, lgb_models, Xt, Yt, Xv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5a2d1b715cbc43b917f7b434a7cba5f4030aa37b"},"cell_type":"code","source":"scores={}\nthresholds={}\nfor name,(cv_pred, de_pred) in lgb_preds.items():\n    print(name)\n    print(\"Cross validation F1 score\")\n    thresholdNb = evaluatePredictions(y, cv_pred, silent=True)\n    print(\"Development set F1 score\")\n    thresholdNb, scoreNb = evaluatePredictions(yde, de_pred, silent=True)\n    thresholds[name] = thresholdNb\n    scores[name] = scoreNb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ec7c1d63ad13f563f5ef49f4d82c37ce9a8acc2"},"cell_type":"code","source":"graphs = []\nnames = []\nfor name,model in lgb_models.items():\n    count = 1\n    for m in model:\n        m.save_model(name+\"_kf\"+str(count)+\".lgb\", num_iteration=num_rounds)\n        count+=1\n        g = lgb.create_tree_digraph(m, precision=1)\n        graphs.append(g)\n        names.append(name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fac43ee9186592823ec7367d25dbcee090ca74d6"},"cell_type":"code","source":"print(names[0])\ngraphs[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f12215e95b2a62f84f3e7a55e60c9f874d2902e","scrolled":false},"cell_type":"code","source":"print(names[24])\ngraphs[24]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a0e5e25881f03e2dae99f490fdfdb24b959bc42"},"cell_type":"code","source":"com_cv_pred=0\ncom_de_pred=0\nfor name,(cv_pred, de_pred) in lgb_preds.items():\n    com_cv_pred += 1/len(lgb_preds)*cv_pred\n    com_de_pred += 1/len(lgb_preds)*de_pred\nprint(\"Cross validation F1 score\")\nthresholdNb = evaluatePredictions(y, com_cv_pred, silent=True)\nprint(\"Development set F1 score\")\nthresholdNb,scoreNb = evaluatePredictions(yde, com_de_pred, silent=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a835f1e3aa25e5b645b0766aede3b5d56afd681"},"cell_type":"markdown","source":"## Loading saved models"},{"metadata":{"trusted":true,"_uuid":"be668f45979f746b71b27854e4cb255b91381637"},"cell_type":"code","source":"lgb_models = {}\nfor f in os.listdir(\".\"):\n    if f.startswith(\"lgb\"):\n#         print(f)\n        fname = f\n        model = lgb.Booster(model_file=fname)\n        lgb_models[f] = model\nprint(len(lgb_models))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"832de2d8cf13173227152347aba18ab4aba79112"},"cell_type":"code","source":"train_stack = None\nval_stack = None\ntest_stack = None\nfor name,model in lgb_models.items():\n    print(name)\n    preds = model.predict(Xt)\n    de_preds = model.predict(Xv)\n    test_preds = model.predict(Xtest)\n    if train_stack is None:\n        train_stack = (preds.reshape(-1,1))\n        val_stack = (de_preds.reshape(-1,1))\n        test_stack = (test_preds.reshape(-1,1))\n    else:\n        train_stack = np.hstack((train_stack, (preds.reshape(-1,1))))\n        val_stack = np.hstack((val_stack, (de_preds.reshape(-1,1))))\n        test_stack = np.hstack((test_stack, test_preds.reshape(-1,1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8ef634e9a9ef9413db17bac671e9fe8160dd372"},"cell_type":"code","source":"classifier = LogisticRegression(class_weight = \"balanced\", C=0.001, solver='lbfgs', verbose=1)\nclassifier.fit(train_stack, y)\ntr_preds = classifier.predict_proba(train_stack)[:,1]\nval_preds = classifier.predict_proba(val_stack)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7444139e44961a82580f8df5a9eb7e3e36fc2472"},"cell_type":"code","source":"test_preds = classifier.predict_proba(test_stack)[:,1]\nprint(test_preds)\ntest_text.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df44ae1f7a9fa118e17e797cb0e2f45baf7a11a0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a458d3e2793fdc8951c02bf1af078fda0e983e89"},"cell_type":"code","source":"evaluatePredictions(y, tr_preds, silent=True)\nevaluatePredictions(yde, val_preds, silent=True)\nprint(accuracy_score(y, tr_preds>=0.86))\nprint(accuracy_score(yde, val_preds>0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e7eadc01e209b5d6935fc04c63510c00c380dc2"},"cell_type":"code","source":"pred_test_y = (test_preds > 0.68) + 0\nones = np.where(pred_test_y > 0)[0]\nprint(pred_test_y.dtype)\nsubmit_df = pd.DataFrame({\"qid\": test[\"qid\"], \"prediction\": pred_test_y})\nprint(submit_df['prediction'].value_counts())\nprint(ones)\nonesPred = test_text.iloc[ones]\nonesPred[330:380]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"642cfc30ec32408a83d18596483be2fd67309dfe"},"cell_type":"code","source":"onesPred[4434]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15a488ca7a1b38267f86deb61283ff2047c19004"},"cell_type":"code","source":"submit_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23df91d9612eb007eaa1abaf3ff7c14f7792b12e"},"cell_type":"markdown","source":" ## Using given embeddings as features"},{"metadata":{"_uuid":"741945c224e6cd661d6be878f213bce069a0207f"},"cell_type":"markdown","source":"Loading the embeddings file (glove) as embedding index."},{"metadata":{"trusted":true,"_uuid":"ce92224816a6f4bccb20be623619763cefb607db"},"cell_type":"code","source":"# em_file = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n# def get_coefs(word, *arr):\n#     return word, np.asarray(arr, dtype='float32')\n# embedding_index = dict(get_coefs(*d.split(' ')) for d in open(em_file))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8266a031edd3b1f38d6ea394352a9a9e5346568f"},"cell_type":"markdown","source":"**Generating Word2Vector from data we have**"},{"metadata":{"trusted":true,"_uuid":"8fbdf37b9ca54f4c5bd7ba6a126a25ff06a39f32","scrolled":true},"cell_type":"code","source":"# def processWords(X):\n#     return [text_to_word_sequence(row) for row in X]\n\n# res = processWords(train_df['question_text'])\n# print(res[:10])\n# train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2969c1c246096a5a0040d3e0bedc86b034b19fd5"},"cell_type":"code","source":"# w2vModel = Word2Vec(res, size=300, window=5, min_count=5, workers=4)\n# w2v = {w: vec for w, vec in zip(w2vModel.wv.index2word, w2vModel.wv.vectors)}\n# # Word2Vec?\n# del w2vModel\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1388a34108558123d56164643c77ef408210918"},"cell_type":"code","source":"# h1 = embedding_index.get(\"hello\")\n# h2 = w2v.get(\"hello\")\n# print(h1)\n# print(h2)\n# np.corrcoef(h1,h2)[0,1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f312031dd48da572c385f7bd4e18e87b5f19ac6"},"cell_type":"markdown","source":"## Linear model with embeddings\n** Using a transformer to vectorize text with the embeddings using *mean* embeddings approach.**"},{"metadata":{"trusted":true,"_uuid":"c989528c0cedf95943897a209a585007238bae5f","scrolled":false},"cell_type":"code","source":"#Using stop words filter along with keras text to word sequence along with embeddings\nclass MeanEmbeddingVectorizer(object):\n    def __init__(self, embedding_index, stop_words=None, debug=False, useSpacy=False):\n        # todo documentation\n        self.embedding_index = embedding_index\n        if stop_words is None:\n            self.stop_words = set(stopwords.words('english'))\n        self.dim = 300 # we are using 300 dims embeddings\n        self.debug = debug\n        self.useSpacy = useSpacy\n        self.nlp = None\n        if self.useSpacy:\n            self.nlp = spacy.load('en_core_web_sm')\n    \n    def analyzer(self, X):\n        if self.useSpacy: #took long time\n            doc1 = nlp(X)\n            filtered_sentence = [token.lemma_ for token in doc1 if not token.is_stop and token.is_alpha and not token.dep_ == 'punct'and not token.lemma_ == '-PRON-']\n        else:\n            word_tokens = text_to_word_sequence(X) # tokenize given text into words\n            filtered_sentence = [w for w in word_tokens if not w in self.stop_words] # filter stop words\n        return set(filtered_sentence)\n\n        \n    def process(self, X):\n        \n        filtered_sentence = self.analyzer(X)\n        vectors = np.zeros(self.dim)\n        count = 0\n        # get vector from\n        for word in filtered_sentence:\n            w2v = self.embedding_index.get(word)\n            if w2v is not None:\n                vectors = vectors + w2v\n                count += 1\n            elif self.debug:\n                print(\"Word not found on embeddings: \", word)\n        if count > 0:\n            return vectors/count\n        else:\n            return vectors\n        \n    def fit(self,X,y):\n        return self\n    \n    def transform(self, X):\n        return np.array([self.process(words) for words in X ])\n    \n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"284d1c1f0fac2889310740a176368c8b1dfb09a7"},"cell_type":"code","source":"# meVect = MeanEmbeddingVectorizer(embedding_index, debug=False)\n# meVect.fit(train_df.question_text,train_df.target)\n# Xm = meVect.transform(train_df.question_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdc80d8ac7e17cab85faeca0f355ec2d926fff50"},"cell_type":"code","source":"# Ym = train_df.target\n# valYm = val_df.target\n# valXm = meVect.transform(val_df.question_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a0edabf5b081214e7b236181722bf8d600634c6","scrolled":true},"cell_type":"code","source":"# logistic_me = LogisticRegression(random_state=333, class_weight=\"balanced\", verbose=1, C=0.01)\n# logistic_me.fit(Xm, Ym)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9926d087e9f43a9d6d2f4d3a5dbfd7f8547d631"},"cell_type":"code","source":"# prob_predicted_me = logistic_me.predict_proba(valXm)\n# print(prob_predicted_me[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc1c8ad56f9394327c41f724f47bcbb54f906e77","scrolled":false},"cell_type":"code","source":"# evaluatePredictions(valYm, prob_predicted_me[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d813b2dde3f99cfd2c152d0f5f601226cb74aafd"},"cell_type":"code","source":"# trprob_predicted_me = logistic_me.predict_proba(Xm)\n# print(trprob_predicted_me[:,1])\n# evaluatePredictions(Ym, trprob_predicted_me[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6445ed91eb1e0e06b1779c93339ac150b5030e4"},"cell_type":"code","source":"# plotPrecisionRecall(trainYm, trprob_predicted_me[:,1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8537a90935e2dad76c140a77a7b0c3475ccbb320"},"cell_type":"markdown","source":"### TFIDF with Embeddings"},{"metadata":{"trusted":true,"_uuid":"eb13d81e48205acad781c6f25fcc03dad047d287"},"cell_type":"code","source":"class TfidfEmbeddingVectorizer(object):\n    def __init__(self, embedding_index, stop_words=None, debug=False):\n        # todo documentation\n        self.embedding_index = embedding_index\n        if stop_words is None:\n            self.stop_words = set(stopwords.words('english'))\n        self.dim = 300 # we are using 300 dims embeddings\n        self.debug = debug\n        self.word2idf = None\n        \n    def analyzer(self, X):\n        word_tokens = text_to_word_sequence(X) # tokenize given text into words\n        filtered_sentence = [w for w in set(word_tokens) if not w in self.stop_words] # filter stop words        \n        return filtered_sentence\n        \n    def process(self, X):\n        filtered_sentence = self.analyzer(X)\n        vectors = np.zeros(self.dim)\n        total_idf = 0\n        # get vector from\n        for word in filtered_sentence:\n            w2v = self.embedding_index.get(word)\n            if w2v is not None:\n                idf = self.word2idf[word]\n                vectors = vectors + (idf*w2v)\n                total_idf += idf\n            elif self.debug: #todo see what happens if we use word2vec here\n                print(\"Word not found on embeddings: \", word)\n        if total_idf > 0:\n            return (vectors)/total_idf\n        else:\n            return vectors \n        \n    def fit(self,X,y):\n        tfidfVect = TfidfVectorizer(analyzer=lambda x: self.analyzer(x))\n        tfidfVect.fit(X,y)\n        max_idf = np.max(tfidfVect.idf_) # for unseen words i.e. they are rare and should have high weight\n        self.word2idf = defaultdict(\n            lambda: max_idf, \n            [(w, tfidfVect.idf_[i]) for w, i in tfidfVect.vocabulary_.items()])\n        return self\n    \n    def transform(self, X):\n        return np.array([self.process(words) for words in X ])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef06cae40dc4d6c9320402b524c481ff497073f6"},"cell_type":"code","source":"# test_array = [\n#     \"This is a sample sentence.\",\n#     \"This is another demo sentence.\",\n#     \"Well, how many more dummy sentence should I add?\",\n#     \"This is a entirely uncorrelated sentence.\"\n# ]\n# target = [1,1,0,0]\n# tfidfEmbVect = TfidfEmbeddingVectorizer(embedding_index, debug=False)\n# tfidfEmbVect = tfidfEmbVect.fit(test_array, target)\n# xdemo = tfidfEmbVect.transform(test_array)\n# from sklearn.preprocessing import StandardScaler\n# # scaler = StandardScaler()\n# # xdemo = scaler.fit_transform(xdemo)\n# print(xdemo)\n# print(np.corrcoef(xdemo[0],xdemo[1])[0,1])\n# print(np.corrcoef(xdemo[0],xdemo[2])[0,1])\n# print(np.corrcoef(xdemo[0],xdemo[3])[0,1])\n# print(np.corrcoef(xdemo[1],xdemo[2])[0,1])\n# print(np.corrcoef(xdemo[1],xdemo[3])[0,1])\n# print(np.corrcoef(xdemo[2],xdemo[3])[0,1])\n# print(tfidfEmbVect.word2idf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54d15a89946d2ad1661f6e09169c37c6ecf46b22"},"cell_type":"code","source":"# tfidfEmbVect = TfidfEmbeddingVectorizer(embedding_index, debug=False)\n# tfidfEmbVect = tfidfEmbVect.fit(train.question_text, train.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4cbfc1c705d16e0ceffb21724bc917379e42127"},"cell_type":"code","source":"# X = tfidfEmbVect.transform(train.question_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41536f658b232b02eca38d469210bd8ae9f528a5"},"cell_type":"code","source":"# # del embedding_index # freeing memory once we have loaded \n# del meVect, embedding_index\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36c886d78ba4557dfe9fde97938df670cb795534"},"cell_type":"code","source":"# Y = train.target\n# trainX, valX, trainY, valY = train_test_split(X, Y, test_size=0.1, random_state=333)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"903c1744bef326ad42a79fda857b0aa94a1c579c"},"cell_type":"code","source":"# logistic_te = LogisticRegression(random_state=333, class_weight=\"balanced\", verbose=1, C=0.01)\n# logistic_te.fit(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11fa9618db56081960cbfbdbb94c78b52467a633"},"cell_type":"code","source":"# prob_predicted_te = logistic_te.predict_proba(valX)\n# evaluatePredictions(valY, prob_predicted_te[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71cd022cd27399facc53b8c81ecdff6b4ed9f816"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}